{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "train = pd.read_parquet('./train_pwm.parquet')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "tr = shuffle(train.sort_values('base_date')[train['base_date'] < 20220701])\n",
    "te = shuffle(train.sort_values('base_date')[train['base_date'] > 20220631])\n",
    "\n",
    "y_train = tr['target']\n",
    "X_train = tr.drop(['day_of_week', 'multi_linked', 'connect_code', 'height_restricted', 'id','base_date', 'target','road_name', 'start_node_name', 'end_node_name','vehicle_restricted'], axis=1)\n",
    "\n",
    "y_test = te['target']\n",
    "X_test = te.drop(['day_of_week', 'multi_linked', 'connect_code', 'height_restricted', 'id','base_date', 'target','road_name', 'start_node_name', 'end_node_name','vehicle_restricted'], axis=1)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 번째 LightGBM 하이퍼 파라미터 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "LR = lgb.LGBMRegressor()\n",
    "\n",
    "\n",
    "parameters = {'max_depth':[10,15,20],\n",
    "              'num_leaves':[150, 250,300],\n",
    "              'learning_rate' : [0.3,0.5, 0.6],\n",
    "            'n_estimators':[100,200,500]\n",
    "             }\n",
    "\n",
    "\n",
    "grid_lr = GridSearchCV(LR, param_grid=parameters, cv=3)\n",
    "\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "scores_df = pd.DataFrame(grid_lr.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'learning_rate': 0.5, 'max_depth': 20, 'num_leaves': 300},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = lgb.LGBMRegressor(random_state = 42,\n",
    "                           max_depth = 20,\n",
    "                           num_leaves = 300,\n",
    "                           learning_rate = 0.5,\n",
    "                           n_estimators = 100,\n",
    "                           \n",
    "                          ).fit(X_train, y_train)\n",
    "\n",
    "pred = LR.predict(X_test)\n",
    "mae = mean_absolute_error(pred, y_test)\n",
    "print(mae)\n",
    "print(LR.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(LR.feature_importances_, X_train.columns)\n",
    "importances.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2번째 LightGBM 하이퍼 파라미터 찾기 (train2 로 작업 위도 경도 삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR2 = lgb.LGBMRegressor()\n",
    "\n",
    "\n",
    "parameters_2 = {'max_depth':[10,15,20],\n",
    "              'num_leaves':[150, 250,300],\n",
    "              'learning_rate' : [0.3,0.5, 0.6],\n",
    "            'n_estimators':[100,200,500]\n",
    "             }\n",
    "\n",
    "\n",
    "grid_lr_2 = GridSearchCV(LR2, param_grid=parameters_2, cv=3)\n",
    "\n",
    "\n",
    "grid_lr_2.fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "scores_df = pd.DataFrame(grid_lr_2.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate 0.3, max_depth: 10 , n_estimators:100,num_leaves:150 2번째 파라미터값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR2 = lgb.LGBMRegressor()\n",
    "LR2 = lgb.LGBMRegressor(random_state = 42,\n",
    "                           max_depth = 20,\n",
    "                           num_leaves = 300,\n",
    "                           learning_rate = 0.5,\n",
    "                           n_estimators = 100,\n",
    "                           \n",
    "                          ).fit(X_train2, y_train2)\n",
    "\n",
    "pred2 = LR2.predict(X_test2)\n",
    "mae2 = mean_absolute_error(pred2, y_test2)\n",
    "print(mae2)\n",
    "print(LR2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR2 = lgb.LGBMRegressor(random_state = 42,\n",
    "                           max_depth = 10,\n",
    "                           num_leaves = 150,\n",
    "                           learning_rate = 0.3,\n",
    "                           n_estimators = 100,\n",
    "                           \n",
    "                          ).fit(X_train2, y_train2)\n",
    "\n",
    "pred2 = LR2.predict(X_test2)\n",
    "mae2 = mean_absolute_error(pred2, y_test2)\n",
    "print(mae2)\n",
    "print(LR2.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest 모델 사용 (첫 번째)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={\n",
    "    'n_estimators':[100],\n",
    "    'max_depth':[6,8,10,12],\n",
    "    'min_samples_leaf':[8,12,18],\n",
    "    'min_samples_split':[8,16,20]\n",
    "}\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "grid_cv = GridSearchCV(rfr, param_grid=params, cv=2, n_jobs=-1)\n",
    "grid_cv.fit(X_train,y_train)\n",
    "print(f\"Best Param: {grid_cv.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_depth=12,min_samples_leaf :8,min_samples_split:20,n_estimators:100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=12,min_samples_leaf=8,min_samples_split=20,n_estimators=100).fit(X_train, y_train)\n",
    "pred=rfr.predict(X_test)\n",
    "mae=mean_absolute_error(pred,y_test)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest 2번째 하이퍼파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 파라미터를 찾는 중...\n",
    "params_2 ={\n",
    "    'n_estimators':[100],\n",
    "    'max_depth':[6,8,10,12],\n",
    "    'min_samples_leaf':[8,12,18],\n",
    "    'min_samples_split':[8,16,20]\n",
    "}\n",
    "\n",
    "rfr_2 = RandomForestRegressor()\n",
    "grid_cv__2 = GridSearchCV(rfr_2, param_grid=params_2, cv=2, n_jobs=-1)\n",
    "grid_cv__2.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_2 = RandomForestRegressor(max_depth=12,min_samples_leaf=8,min_samples_split=20,n_estimators=100).fit(X_train2, y_train2)\n",
    "pred_2=rfr_2.predict(X_test2)\n",
    "mae_2=mean_absolute_error(pred_2,y_test2)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr__2 = RandomForestRegressor(max_depth=12,min_samples_leaf=8,min_samples_split=18,n_estimators=100).fit(X_train2, y_train2)\n",
    "pred__2=rfr__2.predict(X_test2)\n",
    "mae__2=mean_absolute_error(pred__2,y_test2)\n",
    "print(mae__2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 발표 후 피드백 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩 데이터 전처리 후에 아래 데이터 나누는 코드 실행\n",
    "\n",
    "dawn = [0,1,2,3,4,5]\n",
    "morning = [6,7,8,9,10,11]\n",
    "daytime = [12,13,14,15,16,17]\n",
    "night = [18,19,20,21,22,23]\n",
    "\n",
    "hour_label = []\n",
    "\n",
    "for row in train['base_hour']:\n",
    "    if row in dawn:\n",
    "        hour_label.append(0)   # 새벽 0\n",
    "    elif row in morning:\n",
    "        hour_label.append(1)   # 오전 1\n",
    "    elif row in daytime:\n",
    "        hour_label.append(2)   # 오후 2\n",
    "    elif row in night:\n",
    "        hour_label.append(3)   # 저녁 3\n",
    "\n",
    "train['hour_label'] = hour_label\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩(시간) 테스트\n",
    "\n",
    "min_num = 10\n",
    "min_stack = 0\n",
    "stop_num = 3\n",
    "\n",
    "LR = lgb.LGBMRegressor(random_state = 42,\n",
    "                       max_depth = 19,\n",
    "                       num_leaves = 187,\n",
    "                       n_estimators = 1000,\n",
    "                       learning_rate = 0.3,\n",
    "                      ).fit(X_train, y_train)\n",
    "\n",
    "pred = LR.predict(X_test)\n",
    "mae = mean_absolute_error(pred, y_test)\n",
    "\n",
    "\n",
    "# mae 값이 3.55와 근접하다면 for문으로 파라미터 테스트 간단하게 또 진행하도록 하겠습니다.\n",
    "# 근접하다면 말해주세용\n",
    "print('in_holidays : ', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot encoding 후 3.55값이 좋게 나타남."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04ac131e6d54cabd38ce0aa757fc9ec3b740783634967f4d721ee072aca12caf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ds_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
